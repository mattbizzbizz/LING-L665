Examine datafile 'train_small_features_fixed.csv' gave the following results:
Number of Features: 94
InputFormat       : C4.5

Phase 1: Reading Datafile: train_small_features_fixed.csv
Start:          0 @ Thu Feb 23 16:34:53 2023
Finished:   12500 @ Thu Feb 23 16:34:54 2023
Calculating Entropy         Thu Feb 23 16:34:54 2023
Lines of data     : 12500
DB Entropy        : 1.2062323
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      2	6.1156009e-06	0.00048561671
    2      2	0.0028805946	0.076566026
    3      1	0.0000000	0.0000000
    4      2	0.00057268531	0.031981455
    5      2	0.00029460545	0.0010791702
    6      2	0.00050990065	0.013786914
    7      1	0.0000000	0.0000000
    8      2	0.00013209034	0.040867918
    9      1	0.0000000	0.0000000
   10      2	0.00038003659	0.063506954
   11      2	0.011894815	0.14722556
   12      1	0.0000000	0.0000000
   13      1	0.0000000	0.0000000
   14      1	0.0000000	0.0000000
   15      1	0.0000000	0.0000000
   16      2	0.00013209034	0.040867918
   17      2	0.00018876644	0.15675903
   18      2	8.8055939e-05	0.039164603
   19      2	0.0040281129	0.072130236
   20      1	0.0000000	0.0000000
   21      1	0.0000000	0.0000000
   22      1	0.0000000	0.0000000
   23      2	2.4062117e-05	0.0035091508
   24      2	0.00040530644	0.014590449
   25      2	5.6412911e-05	0.017453799
   26      2	0.0032699980	0.063943698
   27      2	0.00035080296	0.083990993
   28      2	0.00024261009	0.20147290
   29      2	0.00018876644	0.15675903
   30      2	4.4025825e-05	0.036560766
   31      1	0.0000000	0.0000000
   32      2	0.00027391406	0.029189900
   33      2	5.1778890e-05	0.0086526395
   34      1	0.0000000	0.0000000
   35      1	0.0000000	0.0000000
   36      1	0.0000000	0.0000000
   37      1	0.0000000	0.0000000
   38      1	0.0000000	0.0000000
   39      1	0.0000000	0.0000000
   40      2	0.0019578198	0.037416863
   41      1	0.0000000	0.0000000
   42      2	0.00016550847	0.0072132273
   43      2	0.0035445153	0.046983481
   44      2	0.00018876644	0.15675903
   45      1	0.0000000	0.0000000
   46      1	0.0000000	0.0000000
   47      1	0.0000000	0.0000000
   48      1	0.0000000	0.0000000
   49      2	4.4025825e-05	0.036560766
   50      1	0.0000000	0.0000000
   51      2	8.8055939e-05	0.039164603
   52      1	0.0000000	0.0000000
   53      2	3.9100879e-05	0.0027641321
   54      1	0.0000000	0.0000000
   55      1	0.0000000	0.0000000
   56      2	0.00024261009	0.20147290
   57      2	0.00069174616	0.042125618
   58      2	0.00025330553	0.060647673
   59      2	0.00080652556	0.034106863
   60      2	0.00018876644	0.15675903
   61      1	0.0000000	0.0000000
   62      2	8.8055939e-05	0.039164603
   63      2	0.00048528653	0.21584068
   64      1	0.0000000	0.0000000
   65      2	0.0015876376	0.055793986
   66      2	0.0038098741	0.16111436
   67      1	0.0000000	0.0000000
   68      1	0.0000000	0.0000000
   69      1	0.0000000	0.0000000
   70      2	9.4983653e-05	0.029387343
   71      2	0.00094421404	0.18542915
   72      2	0.00017612904	0.042169692
   73      1	0.0000000	0.0000000
   74      2	0.00040249488	0.067259902
   75      1	0.0000000	0.0000000
   76      2	0.0033782896	0.11597842
   77      2	0.0016018941	0.097551363
   78      2	0.00018876644	0.15675903
   79      1	0.0000000	0.0000000
   80      2	5.6412911e-05	0.017453799
   81      1	0.0000000	0.0000000
   82      1	0.0000000	0.0000000
   83      1	0.0000000	0.0000000
   84      1	0.0000000	0.0000000
   85      2	0.00017560955	0.022767408
   86      2	0.0014049698	0.099320585
   87      1	0.0000000	0.0000000
   88      2	0.00087732722	0.086002383
   89      1	0.0000000	0.0000000
   90      2	0.00024261009	0.20147290
   91      2	0.00011506373	0.027549132
   92      1	0.0000000	0.0000000
   93      2	0.00024261009	0.20147290
   94      1	0.0000000	0.0000000

Preparation took 0 seconds, 456 milliseconds and 136 microseconds
Feature Permutation based on GainRatio/Values :
< 63, 28, 56, 90, 93, 71, 66, 17, 29, 44, 60, 78, 11, 76, 86, 77, 88, 27, 2, 19, 74, 26, 10, 58, 65, 43, 72, 57, 8, 16, 18, 51, 62, 40, 30, 49, 59, 4, 70, 32, 91, 85, 25, 80, 24, 6, 33, 42, 23, 53, 5, 1, 3, 7, 9, 12, 13, 14, 15, 20, 21, 22, 31, 34, 35, 36, 37, 38, 39, 41, 45, 46, 47, 48, 50, 52, 54, 55, 61, 64, 67, 68, 69, 73, 75, 79, 81, 82, 83, 84, 87, 89, 92, 94 >
Phase 2: Building multi index on Datafile: train_small_features_fixed.csv
Start:          0 @ Thu Feb 23 16:34:54 2023
Finished:   12500 @ Thu Feb 23 16:34:54 2023

Phase 3: Learning from Datafile: train_small_features_fixed.csv
Start:          0 @ Thu Feb 23 16:34:54 2023
Finished:   12500 @ Thu Feb 23 16:34:55 2023

Size of InstanceBase = 6579 Nodes, (263160 bytes), 31.43 % compression
Learning took 0 seconds, 865 milliseconds and 366 microseconds
Examine datafile 'test_small_features_fixed.csv' gave the following results:
Number of Features: 94
InputFormat       : C4.5


Starting to test, Testfile: test_small_features_fixed.csv
Writing output in:          test_small_features_fixed.csv.IB1.O.gr.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.000485616706151
Feature 2	 : 0.076566025967724
Feature 3	 : 0.000000000000000
Feature 4	 : 0.031981455137642
Feature 5	 : 0.001079170154454
Feature 6	 : 0.013786913956932
Feature 7	 : 0.000000000000000
Feature 8	 : 0.040867918393330
Feature 9	 : 0.000000000000000
Feature 10	 : 0.063506954277033
Feature 11	 : 0.147225564314966
Feature 12	 : 0.000000000000000
Feature 13	 : 0.000000000000000
Feature 14	 : 0.000000000000000
Feature 15	 : 0.000000000000000
Feature 16	 : 0.040867918393330
Feature 17	 : 0.156759032606363
Feature 18	 : 0.039164602774290
Feature 19	 : 0.072130236321569
Feature 20	 : 0.000000000000000
Feature 21	 : 0.000000000000000
Feature 22	 : 0.000000000000000
Feature 23	 : 0.003509150766606
Feature 24	 : 0.014590449460672
Feature 25	 : 0.017453798583882
Feature 26	 : 0.063943698117636
Feature 27	 : 0.083990993368399
Feature 28	 : 0.201472904316529
Feature 29	 : 0.156759032606363
Feature 30	 : 0.036560766494479
Feature 31	 : 0.000000000000000
Feature 32	 : 0.029189900457195
Feature 33	 : 0.008652639471243
Feature 34	 : 0.000000000000000
Feature 35	 : 0.000000000000000
Feature 36	 : 0.000000000000000
Feature 37	 : 0.000000000000000
Feature 38	 : 0.000000000000000
Feature 39	 : 0.000000000000000
Feature 40	 : 0.037416862752993
Feature 41	 : 0.000000000000000
Feature 42	 : 0.007213227251988
Feature 43	 : 0.046983480624639
Feature 44	 : 0.156759032606363
Feature 45	 : 0.000000000000000
Feature 46	 : 0.000000000000000
Feature 47	 : 0.000000000000000
Feature 48	 : 0.000000000000000
Feature 49	 : 0.036560766494479
Feature 50	 : 0.000000000000000
Feature 51	 : 0.039164602774290
Feature 52	 : 0.000000000000000
Feature 53	 : 0.002764132077450
Feature 54	 : 0.000000000000000
Feature 55	 : 0.000000000000000
Feature 56	 : 0.201472904316529
Feature 57	 : 0.042125618359878
Feature 58	 : 0.060647673314718
Feature 59	 : 0.034106862868033
Feature 60	 : 0.156759032606363
Feature 61	 : 0.000000000000000
Feature 62	 : 0.039164602774290
Feature 63	 : 0.215840684874317
Feature 64	 : 0.000000000000000
Feature 65	 : 0.055793986405899
Feature 66	 : 0.161114363140718
Feature 67	 : 0.000000000000000
Feature 68	 : 0.000000000000000
Feature 69	 : 0.000000000000000
Feature 70	 : 0.029387342890360
Feature 71	 : 0.185429148035638
Feature 72	 : 0.042169692242615
Feature 73	 : 0.000000000000000
Feature 74	 : 0.067259902385297
Feature 75	 : 0.000000000000000
Feature 76	 : 0.115978420922213
Feature 77	 : 0.097551362531923
Feature 78	 : 0.156759032606363
Feature 79	 : 0.000000000000000
Feature 80	 : 0.017453798583882
Feature 81	 : 0.000000000000000
Feature 82	 : 0.000000000000000
Feature 83	 : 0.000000000000000
Feature 84	 : 0.000000000000000
Feature 85	 : 0.022767407567842
Feature 86	 : 0.099320585121645
Feature 87	 : 0.000000000000000
Feature 88	 : 0.086002383296115
Feature 89	 : 0.000000000000000
Feature 90	 : 0.201472904316529
Feature 91	 : 0.027549131736620
Feature 92	 : 0.000000000000000
Feature 93	 : 0.201472904316529
Feature 94	 : 0.000000000000000

Tested:      1 @ Thu Feb 23 16:34:55 2023
Tested:      2 @ Thu Feb 23 16:34:55 2023
Tested:      3 @ Thu Feb 23 16:34:55 2023
Tested:      4 @ Thu Feb 23 16:34:55 2023
Tested:      5 @ Thu Feb 23 16:34:55 2023
Tested:      6 @ Thu Feb 23 16:34:55 2023
Tested:      7 @ Thu Feb 23 16:34:55 2023
Tested:      8 @ Thu Feb 23 16:34:55 2023
Tested:      9 @ Thu Feb 23 16:34:55 2023
Tested:     10 @ Thu Feb 23 16:34:55 2023
Tested:    100 @ Thu Feb 23 16:34:55 2023
Tested:   1000 @ Thu Feb 23 16:34:55 2023
Ready:    1572 @ Thu Feb 23 16:34:55 2023
Seconds taken: 0.1072 (14658.57 p/s)

overall accuracy:        0.692112  (1088/1572), of which 1568 exact matches 
